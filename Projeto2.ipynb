{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 13/Set at√© √†s 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "At√© o dia 06 de Setembro √†s 23:59, o notebook e o xlsx devem estar no Github com as seguintes evid√™ncias: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste j√° classificado.\n",
    "    \n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conex√£o com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que ser√£o utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados √© necess√°rio ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda n√£o tenha uma: https://twitter.com/signup\n",
    "1. Depois √© necess√°rio registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote tamb√©m:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATEN√á√ÉO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele cont√©m as chaves necess√°rias para realizar as opera√ß√µes no twitter de forma autom√°tica e portanto √© equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as opera√ß√µes manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo n√£o precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @dudabicalhocd\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, n√£o haver√° uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Bradesco'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 400",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-348-910742af87dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmsgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproduto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mmsgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\duda\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\duda\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;31m# Reached end of current page, get the next page...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\duda\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__self__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\duda\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;31m# Set pagination mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\duda\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Twitter error response: status code = 400"
     ]
    }
   ],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora voc√™ deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem √© relevante ou n√£o.<br /> \n",
    "N√£o se esque√ßa de colocar um nome para a coluna na c√©lula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu c√≥digo abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duda\\Documents\\cdd\\Projeto2-CD\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "dados = pd.read_excel('Bradesco.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "#pegando os dados interessantes para nos, Relevantes\n",
    "dr= dados.Respostas[dados.Relevancia=='r']\n",
    "print(len(dr))\n",
    "probder= 91/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "#Irrelevantes\n",
    "di= dados.Respostas[dados.Relevancia=='i']\n",
    "print(len(di))\n",
    "probdei=209/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dicior={} #dicionario que contem a palavra e a quantidade de vezes que ela aparece.\n",
    "palavras=[]\n",
    "Desconsiderar=0 #palavras que podemos desconsiderar, como sites\n",
    "# limpando as palavras e as adicionando a um dicionario\n",
    "for x in dr:\n",
    "    nomes=x.split()\n",
    "    for y in nomes:\n",
    "        p2=[]\n",
    "        if y[0]=='h' and y[1]=='t':\n",
    "            y='.'\n",
    "            Desconsiderar+=1\n",
    "        if y[0]== '@':\n",
    "            y='.'\n",
    "            Desconsiderar+=1\n",
    "        for i in y : \n",
    "            if i!= \":\" and i!=\"'\" and i!='\"' and i!=' ' and i!= \",\" and i!= \".\" and i!='?'and i!='!' and i!='(' and i!=')' :\n",
    "                p2.append(i)\n",
    "        a=\"\".join(p2)\n",
    "        palavras.append(a)\n",
    "        if x in dicior:\n",
    "            dicior[y]+=1\n",
    "        else:\n",
    "            dicior[y]=1\n",
    "        \n",
    "            \n",
    "#print(dicior)\n",
    "#print(palavras)\n",
    "\n",
    "#total de palavras relevantes\n",
    "tr=sum(dicior.values())-Desconsiderar-dicior[\"bradesco\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585\n"
     ]
    }
   ],
   "source": [
    "dicioi={} #dicionario que contem a palavra e a quantidade de vezes que ela aparece.\n",
    "palavrasi=[]\n",
    "Desconsiderari=0 #palavras que podemos desconsiderar, como sites\n",
    "# limpando as palavras e as adicionando a um dicionario\n",
    "for x in di:\n",
    "    nomes=x.split()\n",
    "    for y in nomes:\n",
    "        p2=[]\n",
    "        if y[0]=='h' and y[1]=='t':\n",
    "            y='.'\n",
    "            Desconsiderari+=1\n",
    "        if y[0]== '@':\n",
    "            y='.'\n",
    "            Desconsiderari+=1  \n",
    "        for i in y:\n",
    "            if i!= \":\" and i!=\"'\" and i!='\"' and i!=' ' and i!= \",\" and i!= \".\" and i!='?'and i!='!' and i!='(' and i!=')' and i!='‚Ä¶' :\n",
    "                p2.append(i)\n",
    "        a=\"\".join(p2)\n",
    "        palavrasi.append(a)\n",
    "        if y in dicioi:\n",
    "            dicioi[y]+=1\n",
    "        else:\n",
    "            dicioi[y]=1\n",
    "\n",
    "#print(dicioi)\n",
    "#print(palavrasi)\n",
    "\n",
    "#total de palavras irrelevantes\n",
    "ti=sum(dicioi.values())-Desconsiderari- dicioi[\"bradesco\"]\n",
    "print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295\n"
     ]
    }
   ],
   "source": [
    "#total de palavras existentes nos tweets\n",
    "soma=len(dicioi)\n",
    "for i in dicior:\n",
    "    if i in dicioi:\n",
    "        soma+=0\n",
    "    else:\n",
    "        soma+=1\n",
    "\n",
    "t=soma \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.91587694999271e-10\n"
     ]
    }
   ],
   "source": [
    "#probabilidade da frase ser relevante\n",
    "\n",
    "frase=\" bradesco muito ruim\" #frase de exemplo\n",
    "def probabr(frase,dicior,tr,t):\n",
    "    nomes=frase.split()\n",
    "    pfr=1\n",
    "    for i in nomes:\n",
    "        if i in dicior and i!= \"bradesco\":\n",
    "            pa=(dicior[i]+1)/(tr+t)\n",
    "            pfr*=pa\n",
    "        else:\n",
    "            pa=1/(tr+t)\n",
    "            pfr*=pa\n",
    "    return pfr\n",
    "    \n",
    "print(probabr(frase,dicior,tr,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4240083797811486e-11\n"
     ]
    }
   ],
   "source": [
    "#probabilidade da frase ser irrelevante\n",
    "\n",
    "frase=\" bradesco muito ruim\"\n",
    "def probabi(frase,dicioi,ti,t):\n",
    "    nomes=frase.split()\n",
    "    pfi=1\n",
    "    for i in nomes:\n",
    "        if i in dicioi and i != \"bradesco\":\n",
    "            pa= (dicioi[i]+1)/(ti+t)\n",
    "            pfi*=pa\n",
    "        else:\n",
    "            pa=1/(ti+t)\n",
    "            pfi*=pa\n",
    "    return pfi\n",
    "print(probabi(frase,dicioi,ti,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√â relevante\n"
     ]
    }
   ],
   "source": [
    "#comparando qual probabilidade √© maior, para vermos se a frase √© ou n√£o releante\n",
    "if probabi(frase,dicioi,ti,t)<probabr(frase,dicior,tr,t):\n",
    "    print('√â relevante')\n",
    "else:\n",
    "    print('√â irrelevante')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duda\\Documents\\cdd\\Projeto2-CD\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "dados2 = pd.read_excel('Bradesco.xlsx', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegando os dados para a analise\n",
    "dados2.head()\n",
    "d2= dados2.Tweets\n",
    "dad2=dados2.Relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabrt(frase,dicior,tr,t):\n",
    "    pfr=1\n",
    "    for i in frase:\n",
    "        if i in dicior and i!= \"bradesco\":\n",
    "            pa=(dicior[i]+1)/(tr+t)\n",
    "            pfr*=pa\n",
    "        else:\n",
    "            pa=1/(tr+t)\n",
    "            pfr*=pa\n",
    "    return pfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabit(frase,dicioi,ti,t):\n",
    "    pfi=1\n",
    "    for i in frase:\n",
    "        if i in dicioi and i != \"bradesco\":\n",
    "            pa= (dicioi[i]+1)/(ti+t)\n",
    "            pfi*=pa\n",
    "        else:\n",
    "            pa=1/(ti+t)\n",
    "            pfi*=pa\n",
    "    return pfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=[]\n",
    "palavrasi=[]\n",
    "nomes2=[]\n",
    "frases=[]\n",
    "\n",
    "\n",
    "for x in d2:\n",
    "    nomes=x.split()\n",
    "    k=0\n",
    "    nomes2=[]\n",
    "    for y in nomes: \n",
    "        \n",
    "        \n",
    "        p2=[] \n",
    "        for i in y:\n",
    "            if i!= \":\" and i!=\"'\" and i!='\"' and i!=' ' and i!= \",\" and i!= \".\" and i!='?'and i!='!' and i!='(' and i!=')' and i!='‚Ä¶' :\n",
    "                p2.append(i)\n",
    "    \n",
    "        a=\"\".join(p2)\n",
    "        \n",
    "        \n",
    "        if y[0]!= \"@\":\n",
    "            if len(y)>6:\n",
    "                if y[0]!=\"h\" and y[1]!= \"t\":\n",
    "                    nomes2.append(nomes[k])\n",
    "            else:\n",
    "                nomes2.append(nomes[k])\n",
    "        k+=1 \n",
    "    frases.append(nomes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "11\n",
      "11\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "Relevancia2=[]\n",
    "ii=0\n",
    "ir=0\n",
    "rr=0\n",
    "ri=0\n",
    "\n",
    "#definindo a relevancia de cada frase da base Teste calculada pelo nosso c√≥digo\n",
    "for i in frases: \n",
    "    \n",
    "    pi= probabit(i,dicioi,ti,t)\n",
    "    pr= probabrt(i,dicior,tr,t)\n",
    "    if pi<pr:\n",
    "        Relevancia2.append('r')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Relevancia2.append('i')\n",
    "        \n",
    "    \n",
    "\n",
    "#fazendo uma lista de relevancia marcada por n√≥s da base Teste\n",
    "Relevancia=[]\n",
    "for i in dad2:\n",
    "    Relevancia.append(i)\n",
    "    \n",
    "#comparando os resultados    \n",
    "for x in range(len(Relevancia2)):\n",
    "    if Relevancia[x]=='i' and Relevancia2[x]=='i':\n",
    "        ii+=1\n",
    "    if Relevancia[x]=='i' and Relevancia2[x]=='r':\n",
    "        ir+=1\n",
    "    if Relevancia[x]=='r' and Relevancia2[x]=='r':\n",
    "        rr+=1\n",
    "    if Relevancia[x]=='r' and Relevancia2[x]=='i':\n",
    "        ri+=1\n",
    "            \n",
    "\n",
    "print(ii)\n",
    "print(ir)\n",
    "print(rr)\n",
    "print(ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for x in range(len(Relevancia)):\n",
    "    #if Relevancia[x]==\"i\" and Relevancia[x]!=Relevancia2[x]:\n",
    "        #print(x)\n",
    "        #print(frases[x])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(len(Relevancia)):\n",
    "    #if Relevancia[x]==\"r\" and Relevancia[x]!=Relevancia2[x]:\n",
    "        #print(x)\n",
    "        #print(frases[x])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pri =\n",
      "78.84615384615384\n",
      "prr =\n",
      "21.153846153846153\n",
      "pii =\n",
      "92.56756756756756\n",
      "pir =\n",
      "7.4324324324324325\n"
     ]
    }
   ],
   "source": [
    "#Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "pri=ri/52 *100\n",
    "print('pri =')\n",
    "print(pri)\n",
    "#Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "prr=rr/52*100\n",
    "print('prr =')\n",
    "print(prr)\n",
    "#Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "pii=ii/148*100\n",
    "print('pii =')\n",
    "print(pii)\n",
    "#Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "pir=ir/148*100\n",
    "print('pir =')\n",
    "print(pir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva sua conclus√£o aqui.<br />\n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o <br />\n",
    "Podemos concluir que nosso Classificador pode analisar bem os dados considerados irrelevantes, apresentando uma porcentagem de aproximadamente 92,5% de acertos, mas que sua analise sobre os relevantes n√£o foi t√£o boa, com apenas 21% de acertos. <br />\n",
    "<br />\n",
    "As frases irrelevantes que foram marcadas como relevantes,s√£o em grande maioria composta por palavras diferentes que n√£o s√£o usadas com recorr√™ncia, logo, j√° que existem muitas mais frases irrelevantes do que relevantes, a probalidade dessa palvra ser relevante √© maior que a de ser irrelevante j√° que sempre fica 1 dividido pelo n√∫mero de palvras irrelevantes/relevantes somados ao total de palvras.\n",
    "Tendo em vista que fizemos uma limpa nas frases, retiramos html, \"bradesco\" - por ser uma palavra que aparecia muito e n√£o ajuda na classifica√ß√£o, alguns exeplos de frases irrelevantes consideradas relevantes s√£o:\n",
    "-\"tem homem q √© burro os cr meche , os cr pede p ficar no sigilo mas o besta t√° la kkkk um do lado do outro igual bradesco lado a lado c vc üòÇ\"\n",
    "-\"@bradesco sim, fa√ßo periodicamente isso.\"\n",
    "<br />\n",
    "<br />\n",
    "J√°, podemos perceber que as palavras que por n√≥s eram relevantes, mas consideradas irrelevantes pelo sistema, foram consideradas assim pela quantidade de palavras importantes ser grande e o dicion√°rio que usamos como base para as irrelevantes terem maior n√∫mero de palavras, por grande parte dos tweets da base de Treinamento ser considerada Irrelevante,209 de 300 frases, contando com 2687 palavras irrelevantes, e 91 de 300 frases eram relevantes, com 606 palavras diferentes. Conjutamente a isso, existem palavras que aparecem muito e acababam tendo uma influ√™ncia maior do que deveriam nas avalia√ßoes, sendo elas palavras que n√£o definem a relev√¢ncia da frase,mas influenciam mais do que palavras importantes para a avalia√ß√£o.\n",
    "Alguns exeplos de frases relevantes consideradas irrelevantes s√£o:<br />\n",
    "-@bradesco oi isa bom dia. c√° estou na agencia do bradesco e apenas 2 cx funcionando em √©poca de pgto de idosos e sehttps://t.co/bbvr6jsccx<br />\n",
    "-@bradesco t√¥ com dificuldade de tirar o dinheiro da minha conta, me ajuda<br />\n",
    "<br />\n",
    "Teriamos problemas com as palvras de sarcasmo se estivessemos avaliando comentarios bons e ruins, uma vez que, em frases ir√¥icas, as plavras podem passar a atribiuir um valor contr√°rio do usal. No nosso caso, por exemplo, um tweet √© \"o bom mesmo √© esperar a fila do bradesco de manh√£\", ele est√° usando a palvra \"bom\" para atribuir um valor megativo, logo, essa frase poderia ser clasificada como boa, mas ela √© ruim. As frases com duplo negativo sofrem do mesmo problema anterior, uma vez que a  probabilidade de ser ruim da palavra ser√° atribuida duas vezes. Essa probabilidade ficar√° maior,no entato ela deveria diminuir j√° que frase deveria ser classificada como boa, pois um negativo est√° negando o outro.  <br />\n",
    "<br />\n",
    "Essa analise evidencia  a import√¢ncia de uma melhora no projeto, contando com mais caracter√≠sticas para poder distinguir frases relevantes e irrelevantes, e para isso tamb√©m um maior investimento nele. O projeto ajuda no desenvolvimento e melhoria do Banco,que com o primeiro conseguir√° analisar diretamente as opni√µes no twitter relevantes para seu estudo, e assim poder√° saber com mais facilidade os problemas enfrentados por seus usu√°rios. Mesmo com uma porcentagem de acertos das palavras relevantes baixa o classificador mostra um potencial para o futuro, quando possuir uma base de dados maior para analise das rea√ß√µes dos clientes. \n",
    "Para melhorar o projeto deve ser feita uma analise mais minunciosa de palavras que n√£o devem ser contadas para fazer a probaidade das palavras, j√° que elas aparecem muitas vezes e iram colocar um peso maior na classifica√ß√£o que possui mais palavras. Ddeveremos tamb√©m adquirir uma base de dados maiior para avalia√ß√£o de mais tweets.<br />\n",
    "<br />\n",
    "Um diferente cen√°rio para o uso do classificador Naive-Bayes √© no uso dele para classifica√ß√£o de emails spam ou n√£o spam. Um poss√≠vel uso seria para a economia, na bolsa de valores, pegando vari√°veis, como clima, pol√≠tica, dia da semana, e anotando os valores de diferentes a√ß√µes e depois usando esses dados para outras a√ß√µes as avalidas tamb√©m para pr√≥ximos dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
